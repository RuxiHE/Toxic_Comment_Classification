{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a278cd52500e46dd933abd9152f16273":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d94f78f698d4672852d8ebc72fa9901","IPY_MODEL_199d200bd5334c4fa5feee7abb2f985d","IPY_MODEL_02e379a3b5c4432dbdf69a446ec16339"],"layout":"IPY_MODEL_8dbc1c432182467fba19bc079fee41b1"}},"0d94f78f698d4672852d8ebc72fa9901":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f825373b30be415fb7232b730b101868","placeholder":"​","style":"IPY_MODEL_6ff031959bf6405ba398cc5a15817ec4","value":"100%"}},"199d200bd5334c4fa5feee7abb2f985d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f59327ef821b45978e78342da374be3e","max":177,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75b72b151d5747d79b2c9ca636b9aacc","value":177}},"02e379a3b5c4432dbdf69a446ec16339":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cef880beb4d04e7f8575b136d225de7f","placeholder":"​","style":"IPY_MODEL_20f52363c3094fa0a07e4acdf777fd19","value":" 177/177 [00:56&lt;00:00,  4.56it/s]"}},"8dbc1c432182467fba19bc079fee41b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"f825373b30be415fb7232b730b101868":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ff031959bf6405ba398cc5a15817ec4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f59327ef821b45978e78342da374be3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75b72b151d5747d79b2c9ca636b9aacc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cef880beb4d04e7f8575b136d225de7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20f52363c3094fa0a07e4acdf777fd19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8081b3f33a1f4537b1ee94c3a2df5e24":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe496236e24444ef907f339ceb2aa62c","IPY_MODEL_9fedb16bb69a4487bc49a90a08de4604","IPY_MODEL_d8dd9af2db32412388c1a3fc858593db"],"layout":"IPY_MODEL_a1f0f1f4ae334f46addd0adb537e8545"}},"fe496236e24444ef907f339ceb2aa62c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_882ae13ba1ff400c90c3c526f919a128","placeholder":"​","style":"IPY_MODEL_97f969307110456fb0bfd6704cd1ca0d","value":"100%"}},"9fedb16bb69a4487bc49a90a08de4604":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7d82c44ac144c8085f9c52116647ac1","max":1051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_533876ae8e5840518456e4358e596d26","value":1051}},"d8dd9af2db32412388c1a3fc858593db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25cc25fd5c6041aab4411657239d79d1","placeholder":"​","style":"IPY_MODEL_e208f76c4d844be9966bcdb4eb3e426e","value":" 1051/1051 [15:41&lt;00:00,  1.08it/s]"}},"a1f0f1f4ae334f46addd0adb537e8545":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"882ae13ba1ff400c90c3c526f919a128":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97f969307110456fb0bfd6704cd1ca0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7d82c44ac144c8085f9c52116647ac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"533876ae8e5840518456e4358e596d26":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25cc25fd5c6041aab4411657239d79d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e208f76c4d844be9966bcdb4eb3e426e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54c6c0cfdad44d05b2a3ea9c69a39aa5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a3ddfb86cad94ea68dedae59b5cce923","IPY_MODEL_1ab8682db8f34e0d900fe612012a5764","IPY_MODEL_2c4d3e40b7ac46199b5820c267327b42"],"layout":"IPY_MODEL_460325c13fb3479db489ccc37f81005a"}},"a3ddfb86cad94ea68dedae59b5cce923":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_903ad7c018894450811f8b0e3a10c253","placeholder":"​","style":"IPY_MODEL_9ab037319a9a483da59c2f8ceede822e","value":"100%"}},"1ab8682db8f34e0d900fe612012a5764":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a67f907d4764853a6f35b27fce1c00b","max":177,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81f53886a7534f85a7ac7f354dce6535","value":177}},"2c4d3e40b7ac46199b5820c267327b42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4376321787344711aabf9e2119fc0659","placeholder":"​","style":"IPY_MODEL_834de7f1fa734b128547f691ff8b1062","value":" 177/177 [01:16&lt;00:00,  2.87it/s]"}},"460325c13fb3479db489ccc37f81005a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"903ad7c018894450811f8b0e3a10c253":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ab037319a9a483da59c2f8ceede822e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a67f907d4764853a6f35b27fce1c00b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81f53886a7534f85a7ac7f354dce6535":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4376321787344711aabf9e2119fc0659":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"834de7f1fa734b128547f691ff8b1062":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ff00ceecf7546999dc52c9a40664875":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f7bc331ad1842a48d69a990c2f7e25b","IPY_MODEL_64f09c87a8c64a1aa5aa132d737a8e34","IPY_MODEL_bd85be352a8b45e5a1af06c3db7a62e5"],"layout":"IPY_MODEL_e040bc9ae23e4d9995985184f69d976b"}},"9f7bc331ad1842a48d69a990c2f7e25b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91723b0258284e9d816538383e4dc00d","placeholder":"​","style":"IPY_MODEL_4478ebc6f580473dac120f8adb880060","value":"100%"}},"64f09c87a8c64a1aa5aa132d737a8e34":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a48520f7757448383bb5ba46176de07","max":262,"min":0,"orientation":"horizontal","style":"IPY_MODEL_849acb573a4040b9afff4a601f6064c5","value":262}},"bd85be352a8b45e5a1af06c3db7a62e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30d89d99cbc84ae098d2d9cc157be663","placeholder":"​","style":"IPY_MODEL_2c818a35dd4d48ea95d66b4d69516b3f","value":" 262/262 [03:37&lt;00:00,  1.50it/s]"}},"e040bc9ae23e4d9995985184f69d976b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"91723b0258284e9d816538383e4dc00d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4478ebc6f580473dac120f8adb880060":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a48520f7757448383bb5ba46176de07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"849acb573a4040b9afff4a601f6064c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30d89d99cbc84ae098d2d9cc157be663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c818a35dd4d48ea95d66b4d69516b3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":90486,"databundleVersionId":10521459,"sourceType":"competition"},{"sourceId":6892930,"sourceType":"datasetVersion","datasetId":3959783}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Baseline\nThis notebook implments a baseline model, which shows you how to handle the data and to provide a first very simple solution to the problem. You may re-use and modify any part of this notebook.","metadata":{"id":"ZTlgdKiOXI4L"}},{"cell_type":"code","source":"#!pip install torchmetrics --quiet","metadata":{"id":"uq88HwVYYDHB","outputId":"ba7b813f-efa8-4e5e-c417-881fe3c9e964","trusted":true,"execution":{"iopub.status.busy":"2025-01-30T17:20:46.398755Z","iopub.execute_input":"2025-01-30T17:20:46.399145Z","iopub.status.idle":"2025-01-30T17:20:46.404117Z","shell.execute_reply.started":"2025-01-30T17:20:46.399115Z","shell.execute_reply":"2025-01-30T17:20:46.402955Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport csv\nimport torch\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport re\nimport random\nfrom tqdm.notebook import tqdm\nfrom google.colab import drive\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom torchmetrics import AUROC, F1Score\nfrom nltk.corpus import stopwords","metadata":{"id":"bkAdPWLCX5aN","trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:17:14.702728Z","iopub.execute_input":"2025-01-30T19:17:14.702956Z","iopub.status.idle":"2025-01-30T19:17:22.759241Z","shell.execute_reply.started":"2025-01-30T19:17:14.702934Z","shell.execute_reply":"2025-01-30T19:17:22.758106Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n# use weighted loss function due to the extreme imbalance of label\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"tWvjXjZxZ42a","outputId":"90539351-8c88-474e-8e1a-2b4cc1176a00","trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:17:22.760273Z","iopub.execute_input":"2025-01-30T19:17:22.760869Z","iopub.status.idle":"2025-01-30T19:17:22.775372Z","shell.execute_reply.started":"2025-01-30T19:17:22.760839Z","shell.execute_reply":"2025-01-30T19:17:22.774191Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Dataset construction with Fasttext embedding.","metadata":{}},{"cell_type":"markdown","source":"from the code above, we can see that the comment has up to 315 words which is relatively lightweight. And due to the constraint of the time and resource, it is better to try lightweight embedding models. Given that the training set is user-generated-content which contains noise like typo it is recommended to use fasttext for its OOV performance. ","metadata":{}},{"cell_type":"code","source":"import fasttext\nimport fasttext.util\n# fasttext.download_model('cc.en.300.bin')  # need to run this if no fasttext model in local.\nft = fasttext.load_model('/kaggle/input/cc-en-300-bin/cc.en.300.bin')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:17:38.556414Z","iopub.execute_input":"2025-01-30T19:17:38.556783Z","iopub.status.idle":"2025-01-30T19:18:11.623931Z","shell.execute_reply.started":"2025-01-30T19:17:38.556758Z","shell.execute_reply":"2025-01-30T19:18:11.622884Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class FastTextDatasetWithDemographics(Dataset):\n    def __init__(self, data_dir, mode, fasttext_model=None):\n        super(FastTextDatasetWithDemographics, self).__init__()\n        assert mode in ['train', 'val', 'test']\n        self.mode = mode\n\n        # Load the data\n        self.data = pd.read_csv(os.path.join(data_dir, f'{mode}_x.csv'), index_col=0).fillna(\"na\")\n\n        # Load the labels if not the test set\n        if self.mode != 'test':\n            self.label = pd.read_csv(os.path.join(data_dir, f'{mode}_y.csv'))\n\n        # Load FastText model\n        if fasttext_model is None and self.mode == 'train':\n            raise ValueError(\"FastText model must be provided for training.\")\n        self.fasttext_model = fasttext_model\n\n        # Initialize stopwords\n        self.stopwords = set(stopwords.words('english'))\n    \n    def clean_text(self, text):\n        \"\"\"Clean the text by removing special characters and stopwords.\"\"\"\n        # Remove special characters and lower the text\n        text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n        # Remove stopwords\n        text = ' '.join([word for word in text.split() if word not in self.stopwords])\n        return text\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # Extract the text comment\n        x = self.data.iloc[idx, 0]\n        # Replace the newline mark\n        x = x.replace('\\n', ' ').strip()\n        # Clean the text by removing the stopwords.\n        x = self.clean_text(x)\n\n        # Compute FastText embedding\n        x_embedding = self.fasttext_model.get_sentence_vector(x)\n        x_tensor = torch.tensor(x_embedding).float()\n\n        # If it's the test set, return just the embedding and index\n        if self.mode == 'test':\n            return x_tensor, idx\n        else:\n            # Otherwise, return the label and the demographics as well\n            \n            # the label\n            y = torch.tensor([self.label[\"y\"].iloc[idx]]).float()\n            \n            # process the demograhic features\n            demographics = torch.tensor(self.label.iloc[idx,:8].values).float()\n            \n            return x_tensor, y, demographics, idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:18:11.625233Z","iopub.execute_input":"2025-01-30T19:18:11.625539Z","iopub.status.idle":"2025-01-30T19:18:11.636067Z","shell.execute_reply.started":"2025-01-30T19:18:11.625516Z","shell.execute_reply":"2025-01-30T19:18:11.634934Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_dir = \"/kaggle/input/toxic-comment-classification-dsba-2025/kaggle_data/\"\nval_dir = \"/kaggle/input/toxic-comment-classification-dsba-2025/kaggle_data/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:18:11.638150Z","iopub.execute_input":"2025-01-30T19:18:11.638566Z","iopub.status.idle":"2025-01-30T19:18:11.662598Z","shell.execute_reply.started":"2025-01-30T19:18:11.638522Z","shell.execute_reply":"2025-01-30T19:18:11.661502Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_dataset = FastTextDatasetWithDemographics(train_dir, 'train', ft)\nval_dataset = FastTextDatasetWithDemographics(val_dir, 'val', train_dataset.fasttext_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:18:11.663874Z","iopub.execute_input":"2025-01-30T19:18:11.664187Z","iopub.status.idle":"2025-01-30T19:18:15.095477Z","shell.execute_reply.started":"2025-01-30T19:18:11.664147Z","shell.execute_reply":"2025-01-30T19:18:15.094539Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:18:15.096478Z","iopub.execute_input":"2025-01-30T19:18:15.096860Z","iopub.status.idle":"2025-01-30T19:18:15.102361Z","shell.execute_reply.started":"2025-01-30T19:18:15.096824Z","shell.execute_reply":"2025-01-30T19:18:15.101017Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"markdown","source":"We decided to separate streams of embedded text data and the demographic features for the sake of the interpretability of the contribution, flexibility, and a better representation learning.","metadata":{}},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, embedding_dim):\n        super(Attention, self).__init__()\n        self.attention_weights = nn.Linear(embedding_dim,1)\n\n    def forward(self, embeddings):\n        weights = torch.softmax(self.attention_weights(embeddings), dim=1)\n        attended_embeddings = embeddings * weights\n        return attended_embeddings.sum(dim=1)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(ResidualBlock, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.gelu = nn.GELU()\n        self.fc2 = nn.Linear(hidden_dim, input_dim)\n\n    def forward(self, x):\n        residual = x  # Shortcut connection\n        out = self.fc1(x)\n        out = self.gelu(out)\n        out = self.fc2(out)\n        return out + residual  # Add input back to output\n        \nclass EnhancedToxicCommentClassifierWithAttention(nn.Module):\n    def __init__(self, input_dim=300, hidden_dim=512, output_dim=1, num_residual_blocks=1):\n        super(EnhancedToxicCommentClassifierWithAttention, self).__init__()\n        self.attention = Attention(input_dim)\n        self.fc_in = nn.Linear(input_dim, hidden_dim)\n        self.bn = nn.BatchNorm1d(hidden_dim)\n        self.gelu = nn.GELU()\n        self.residual_blocks = nn.ModuleList(\n            [ResidualBlock(hidden_dim, hidden_dim//2) for _ in range(num_residual_blocks)]\n        )\n        self.fc_out = nn.Linear(hidden_dim , output_dim)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, text_embedding):\n        text_embedding = text_embedding.unsqueeze(1)\n\n        x = self.attention(text_embedding)\n        x = self.fc_in(x)\n        x = self.bn(x)\n        x = self.gelu(x)\n        for block in self.residual_blocks:\n            x = block(x)\n        x = self.fc_out(x)\n        return self.sigmoid(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:18:15.103392Z","iopub.execute_input":"2025-01-30T19:18:15.103682Z","iopub.status.idle":"2025-01-30T19:18:15.123813Z","shell.execute_reply.started":"2025-01-30T19:18:15.103648Z","shell.execute_reply":"2025-01-30T19:18:15.122777Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\n\n# initiation of the model\nmodel = EnhancedToxicCommentClassifierWithAttention()\n\n# calculate the weight of each label. \nclasses = pd.read_csv(\"/kaggle/input/toxic-comment-classification-dsba-2025/kaggle_data/train_y.csv\")[\"y\"]\nclass_counts = classes.value_counts().values.tolist()\ntotal_samples = sum(class_counts)\nweights = [total_samples / (len(class_counts) * count) for count in class_counts]\ncriterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([weights[1]])).to(device)\n\n# optimizer\noptimizer = optim.AdamW(model.parameters(), lr=0.05, weight_decay=0.01)\n\n# Use scheduler to better adjust the learning rate to facilidate learning.\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:18:15.124795Z","iopub.execute_input":"2025-01-30T19:18:15.125093Z","iopub.status.idle":"2025-01-30T19:18:16.618185Z","shell.execute_reply.started":"2025-01-30T19:18:15.125068Z","shell.execute_reply":"2025-01-30T19:18:16.617242Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# different version","metadata":{}},{"cell_type":"code","source":"def compute_group_weights(group_accuracies):\n    \"\"\"\n    Compute sample weights inversely proportional to group accuracy.\n    If a sample belongs to multiple groups, its weight is averaged over those groups.\n    \"\"\"\n    group_weights = 1.0 / (group_accuracies + 1e-6)  # Avoid division by zero\n    group_weights /= group_weights.sum()  # Normalize so they sum to 1\n    return torch.tensor(group_weights, dtype=torch.float32).to(device)\n\ndef group_accuracy(prediction, y):\n    \"\"\"\n        Compute the worst group accuracy, with the groups being defined by ['male', 'female', 'LGBTQ',\n        'christian', 'muslim', 'other_religions', 'black', 'white'] for positive and negative toxicity.\n        arguments:\n            prediction [pandas.DataFrame]: dataframe with 2 columns (index and pred)\n            y [pandas.DataFrame]: dataframe containing the metadata\n        returns:\n            wga [float]: worst group accuracy\n    \"\"\"\n    y.loc[prediction.index, 'pred'] = prediction.pred\n\n    categories = ['male', 'female', 'LGBTQ', 'christian', 'muslim', 'other_religions', 'black', 'white']\n    accuracies = []\n    averaged_category_accuracies = []\n    for category in categories:\n        category_accuracies = []\n        label_sizes = []\n        for label in [0, 1]:\n            group = y.loc[y[category] == label]\n            label_sizes.append(len(group))\n            group_accuracy = (group['y'] == (group['pred'] > 0.5)).mean()\n            \n            accuracies.append(group_accuracy)\n            category_accuracies.append(group_accuracy)\n\n        # calculate the averaged accuracy of this category using geometric average. \n        averaged_category_accuracy = np.exp(np.mean(np.log(np.array(category_accuracies) + 1e-6)))\n        averaged_category_accuracies.append(averaged_category_accuracy)\n        \n    wga = np.min(accuracies)\n    averaged_category_accuracies = torch.tensor(averaged_category_accuracies).float().to(device)\n    return wga, averaged_category_accuracies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:18:16.620096Z","iopub.execute_input":"2025-01-30T19:18:16.620713Z","iopub.status.idle":"2025-01-30T19:18:16.628656Z","shell.execute_reply.started":"2025-01-30T19:18:16.620678Z","shell.execute_reply":"2025-01-30T19:18:16.627455Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def train_model(model, optimizer, criterion, dataloader, group_accuracies, device): # paired with FasttextDataset with sample weight based on group performance\n    \"\"\"\n        Train a model for one epoch.\n        arguments:\n            model [torch.nn.Module]: model to evaluate\n            oprimizer [torch.optim]: optimizer used for training\n            criterion [torch.nn.modules.loss]: desired loss to compute\n            dataloader [torch.utils.data.DataLoader]: dataloader used for training\n            device : cpu or gpu\n        returns:\n            dataset_loss [float]: computed loss on the dataset\n            dataset_metric [float]: computed metric on the dataset\n    \"\"\"\n    model.train()\n    model.to(device)\n    \n    losses, predictions, indices = [], [], []\n    for x, y, demographics, idx in tqdm(dataloader, leave=False):\n        x, y, demographics= x.to(device), y.to(device), demographics.to(device)\n        optimizer.zero_grad()\n        pred = model(x)\n        loss = criterion(pred.squeeze(), y.squeeze().float())\n        \n        # compute the weighted loss using the sample weights which derived from the group_accuracies\n        sample_weights = (demographics * compute_group_weights(group_accuracies)).sum(dim=1).to(device)\n        weighted_loss = (loss * sample_weights).mean()  # Apply per-sample weight\n        weighted_loss.backward()\n        optimizer.step()\n\n        losses.extend([weighted_loss.item()] * len(y))\n        predictions.extend(pred.detach().squeeze().tolist())\n        indices.extend(idx.tolist())\n    \n    pred_df = pd.DataFrame({'index': indices, 'pred': predictions})\n    dataset_loss = np.mean(losses)\n    wga, group_accuracies = group_accuracy(pred_df, y = dataloader.dataset.label)\n\n    return dataset_loss, wga, group_accuracies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:18:16.630210Z","iopub.execute_input":"2025-01-30T19:18:16.630647Z","iopub.status.idle":"2025-01-30T19:18:16.657260Z","shell.execute_reply.started":"2025-01-30T19:18:16.630603Z","shell.execute_reply":"2025-01-30T19:18:16.656219Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def evaluate_model(model, dataloader, criterion, group_accuracies, device): # # paired with FasttextDataset with sample weight based on group performance\n    \"\"\"\n        Evaluate the model on a given dataloader.\n        argument:\n            model [torch.nn.Module]: model to evaluate\n            dataloader [torch.utils.data.DataLoader]: dataloader on which to evaluate\n            criterion [torch.nn.modules.loss]: desired loss to compute\n            device : cpu or gpu\n        returns:\n            dataset_loss [float]: computed loss on the dataset\n            dataset_metric [float]: computed metric on the dataset\n    \"\"\"\n    model.eval()\n    model.to(device)\n    losses, predictions, indices = [], [], []\n    for x, y, demographics, idx in tqdm(dataloader, leave=False):\n        x, y, demographics= x.to(device), y.to(device), demographics.to(device)\n        with torch.no_grad():\n            pred = model(x)\n        sample_weights = (demographics * compute_group_weights(group_accuracies)).sum(dim=1).to(device)    \n        loss = criterion(pred.squeeze(), y.squeeze().float())\n\n        # compute the weighted loss using the sample weights which derived from the group_accuracies\n        weighted_loss = (loss * sample_weights).mean() \n        losses.extend([weighted_loss.item()] * len(y))\n        predictions.extend(pred.detach().squeeze().tolist())\n        indices.extend(idx.tolist())\n\n\n    pred_df = pd.DataFrame({'index': indices, 'pred': predictions})\n    dataset_loss = np.mean(losses)\n    wga, group_accuracies = group_accuracy(pred_df, dataloader.dataset.label)\n    return dataset_loss, wga, group_accuracies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:18:16.658363Z","iopub.execute_input":"2025-01-30T19:18:16.658727Z","iopub.status.idle":"2025-01-30T19:18:16.673913Z","shell.execute_reply.started":"2025-01-30T19:18:16.658690Z","shell.execute_reply":"2025-01-30T19:18:16.672780Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ReduceLROnPlateau\n\nmodel = EnhancedToxicCommentClassifierWithAttention()\n\nclasses = pd.read_csv(\"/kaggle/input/toxic-comment-classification-dsba-2025/kaggle_data/train_y.csv\")[\"y\"]\nclass_counts = classes.value_counts().values.tolist()\ntotal_samples = sum(class_counts)\nweights = [total_samples / (len(class_counts) * count) for count in class_counts]\ncriterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([weights[1]])).to(device)\n\noptimizer = optim.AdamW(model.parameters(), lr=0.05, weight_decay=0.01)\n# Use scheduler to better adjust the learning rate to facilidate learning.\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:21:50.809050Z","iopub.execute_input":"2025-01-30T19:21:50.809423Z","iopub.status.idle":"2025-01-30T19:21:51.035845Z","shell.execute_reply.started":"2025-01-30T19:21:50.809394Z","shell.execute_reply":"2025-01-30T19:21:51.034907Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"num_epochs = 10\ngroup_accuracies = torch.full((8,), 0.5, dtype=torch.float32)  # Default accuracy = 50%\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    train_loss, wga, _ = train_model(model,optimizer, criterion, train_dataloader, group_accuracies, device)\n    print(f\"Epoch {epoch + 1} - train Loss: {train_loss:.4f}, WGA: {wga:.4f}\")\n    mlp_val_loss, val_wga, group_accuracies = evaluate_model(model, val_dataloader, criterion, group_accuracies, device)\n    #scheduler.step(mlp_val_loss)\n    print(group_accuracies)\n    print(f\"Epoch {epoch + 1} - evaluation loss {mlp_val_loss:.4f}, WGA: {val_wga:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:21:53.279415Z","iopub.execute_input":"2025-01-30T19:21:53.279747Z","iopub.status.idle":"2025-01-30T19:59:50.509597Z","shell.execute_reply.started":"2025-01-30T19:21:53.279723Z","shell.execute_reply":"2025-01-30T19:59:50.508472Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"<ipython-input-10-236d4c1d977e>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return torch.tensor(group_weights, dtype=torch.float32).to(device)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - train Loss: 0.0664, WGA: 0.6880\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"tensor([0.8710, 0.8800, 0.8205, 0.9002, 0.8231, 0.8621, 0.7791, 0.7954])\nEpoch 1 - evaluation loss 0.0726, WGA: 0.6774\nEpoch 2/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2 - train Loss: 0.0652, WGA: 0.6856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"tensor([0.8710, 0.8800, 0.8205, 0.9002, 0.8231, 0.8621, 0.7791, 0.7956])\nEpoch 2 - evaluation loss 0.0718, WGA: 0.6774\nEpoch 3/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3 - train Loss: 0.0652, WGA: 0.6856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"tensor([0.8710, 0.8800, 0.8205, 0.9002, 0.8231, 0.8621, 0.7791, 0.7956])\nEpoch 3 - evaluation loss 0.0718, WGA: 0.6774\nEpoch 4/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4 - train Loss: 0.0651, WGA: 0.6856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"tensor([0.8710, 0.8800, 0.8205, 0.9002, 0.8231, 0.8621, 0.7791, 0.7956])\nEpoch 4 - evaluation loss 0.0718, WGA: 0.6774\nEpoch 5/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 5 - train Loss: 0.0655, WGA: 0.6830\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"tensor([0.8710, 0.8800, 0.8205, 0.9002, 0.8231, 0.8621, 0.7791, 0.7956])\nEpoch 5 - evaluation loss 0.0718, WGA: 0.6774\nEpoch 6/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 6 - train Loss: 0.0651, WGA: 0.6856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"tensor([0.8710, 0.8800, 0.8205, 0.9002, 0.8231, 0.8621, 0.7791, 0.7956])\nEpoch 6 - evaluation loss 0.0718, WGA: 0.6774\nEpoch 7/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 7 - train Loss: 0.0652, WGA: 0.6856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"tensor([0.8710, 0.8800, 0.8205, 0.9002, 0.8231, 0.8621, 0.7791, 0.7956])\nEpoch 7 - evaluation loss 0.0718, WGA: 0.6774\nEpoch 8/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 8 - train Loss: 0.0652, WGA: 0.6856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"tensor([0.8710, 0.8800, 0.8205, 0.9002, 0.8231, 0.8621, 0.7791, 0.7956])\nEpoch 8 - evaluation loss 0.0718, WGA: 0.6774\nEpoch 9/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 9 - train Loss: 0.0651, WGA: 0.6856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"tensor([0.8710, 0.8800, 0.8205, 0.9002, 0.8231, 0.8621, 0.7791, 0.7956])\nEpoch 9 - evaluation loss 0.0718, WGA: 0.6774\nEpoch 10/10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 10 - train Loss: 0.0650, WGA: 0.6701\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/353 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"tensor([0.8572, 0.8652, 0.8140, 0.8865, 0.8067, 0.8369, 0.7805, 0.7922])\nEpoch 10 - evaluation loss 0.0707, WGA: 0.6937\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Generate Test Result","metadata":{}},{"cell_type":"markdown","source":"Once we are happy with our results, we want to make a prediction on the test set. Your submission `.csv` file should contain 2 columns:\n- ID: with the id of each prediction (do not shuffle to not mix things up)\n- pred: the prediction of the model (thresholded or not)","metadata":{"id":"rSiizvRpr_5J"}},{"cell_type":"code","source":"#model = RandomClassifier()\n#test_dataset = FastTextDataset(train_dir, 'test', train_dataset.fasttext_model)\ntest_dataset = FastTextDatasetWithDemographics(train_dir, 'test', train_dataset.fasttext_model)\ntest_dataloader = DataLoader(test_dataset, batch_size=512, shuffle=False)\nmodel.eval()\ntest_predictions, indices = [], []\nfor x, idx in tqdm(test_dataloader, leave=False):\n    x = x.to(device)\n    with torch.no_grad():\n        pred = (model(x).squeeze() > 0.5).int()\n    test_predictions.extend(pred.tolist())\n    indices.extend(idx.tolist())","metadata":{"id":"TXoPeUTjsxNu","outputId":"fc9b86f3-9e45-413a-e320-70733f1a6d1f","trusted":true,"execution":{"iopub.status.busy":"2025-01-30T20:05:24.716922Z","iopub.execute_input":"2025-01-30T20:05:24.717293Z","iopub.status.idle":"2025-01-30T20:06:09.077871Z","shell.execute_reply.started":"2025-01-30T20:05:24.717266Z","shell.execute_reply":"2025-01-30T20:06:09.076614Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/262 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"pred_df = pd.DataFrame({'ID': indices, 'pred': test_predictions})\npred_df.to_csv('prediction.csv', index=False)","metadata":{"id":"mzlemJhdFwNo","trusted":true,"execution":{"iopub.status.busy":"2025-01-30T20:06:09.079187Z","iopub.execute_input":"2025-01-30T20:06:09.079617Z","iopub.status.idle":"2025-01-30T20:06:09.256343Z","shell.execute_reply.started":"2025-01-30T20:06:09.079587Z","shell.execute_reply":"2025-01-30T20:06:09.255186Z"}},"outputs":[],"execution_count":22}]}